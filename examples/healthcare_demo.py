"""
SEVE Framework - Healthcare Demo
Demonstra√ß√£o de processamento √©tico de dados m√©dicos (HIPAA/LGPD)
"""

import asyncio
import sys
import os
from pathlib import Path

# Adicionar src ao path para importar o framework
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

from seve_framework import SEVECoreV3, SEVEConfig, EthicsLevel

async def run_healthcare_demo():
    print("\nüè• SEVE Framework - Healthcare Adapter Demo")
    print("===========================================\n")
    
    # 1. Configura√ß√£o Espec√≠fica para Sa√∫de
    config = SEVEConfig(
        ethics_level=EthicsLevel.STRICT,
        guardflow_enabled=True
    )
    
    core = SEVECoreV3(config)
    await core.initialize()
    
    # Cen√°rio 1: Acesso n√£o autorizado a prontu√°rio (Deve ser BLOQUEADO)
    print("Caso 1: Tentativa de acesso a prontu√°rio sem token de consentimento")
    access_request = {
        "domain": "healthcare",
        "action": "read_record",
        "patient_id": "PT-998877",
        "data_type": "psychiatric_history",
        "consent_token": None  # Faltando!
    }
    
    result = await core.process_context(access_request, context={"user_role": "nurse"})
    
    if result.status == "ethics_blocked":
        print(f"‚ùå BLOQUEADO: {result.reason}")
        print("   (O sistema protegeu a privacidade do paciente corretamente)\n")
    else:
        print(f"‚ö†Ô∏è FALHA: Acesso permitido indevidamente: {result.status}\n")
        
    # Cen√°rio 2: Processamento de Imagem para Diagn√≥stico (Deve ser APROVADO com Anonimiza√ß√£o)
    print("Caso 2: Processamento de Raio-X com consentimento v√°lido")
    diagnostic_request = {
        "domain": "healthcare",
        "action": "analyze_image",
        "image_id": "IMG-554433",
        "consent_token": "VALID_TOKEN_SHA256",
        "anonymization_required": True
    }
    
    # Simulando aprova√ß√£o para fins de demo (na pr√°tica, validaria o token)
    # Em um sistema real, o GuardFlow verificaria a validade criptogr√°fica do token
    
    # Vamos for√ßar um contexto que o mock do GuardFlow aceite se tiver consentimento
    result_valid = await core.process_context(diagnostic_request, context={"user_role": "doctor"})
    
    # Nota: Como estamos usando o core b√°sico, ele pode bloquear se n√£o tiver regras espec√≠ficas de healthcare carregadas.
    # Mas o importante √© demonstrar o fluxo.
    
    print(f"Status: {result_valid.status}")
    if result_valid.status == "ethics_blocked":
         print(f"Resultado: Bloqueado ({result_valid.reason})")
    else:
         print(f"‚úÖ APROVADO: Imagem enviada para an√°lise (Metadados removidos)")
         print(f"   Audit ID: {result_valid.audit_id}")

if __name__ == "__main__":
    asyncio.run(run_healthcare_demo())
